{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c461f7e3-d5e3-4088-980a-176e6a5aab77",
   "metadata": {},
   "source": [
    "# 5.6.2) Testing the model trained without pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3eedffd-caa6-4b90-9493-eba6833251bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bcc759-f631-4ac6-a30b-644b6ce4f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_sex = pickle.load(open('models/ohe_sex.pkl','rb'))\n",
    "ohe_embarked = pickle.load(open('models/ohe_embarked.pkl','rb'))\n",
    "clf = pickle.load(open('models/clf.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ffb1da-c04f-4651-a3b6-bfacca33549a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 'male', 31.0, 0, 0, 10.5, 'S']], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assumer user inputes Pclass, Gender, Age, SibSp, Parch, Fare, Embarked as:\n",
    "test_input = np.array([2, 'male', 31.0, 0, 0, 10.5, 'S'], dtype=object).reshape(1,7)\n",
    "test_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeccbdd-5e29-4651-9cb6-bf7c8a2ec251",
   "metadata": {},
   "source": [
    "- Why we used reshape()?\n",
    "  - Most Scikit-learn models and transformers like OneHotEncoder, StandardScaler, and .predict() methods expect the input to be 2-dimensional, even if it's just one sample.\n",
    "  - So what's happening?\n",
    "    - [2, 'male', 31.0, 0, 0, 10.5, 'S'] → This is a 1D array (shape = (7,))\n",
    "    - .reshape(1, 7) → Converts it into a 2D array with 1 row and 7 columns\n",
    "    - Shape becomes: (1, 7) → acceptable to transformers and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c143df7b-befa-4920-ba9b-2426bef9dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we need to apply all the transformations on our test_input:\n",
    "test_input_sex = ohe_sex.transform(test_input[:,1].reshape(1,1))\n",
    "test_input_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd9b2f5-ad22-40fb-99b6-82b7b8974856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_embarked = ohe_embarked.transform(test_input[:,-1].reshape(1,1))\n",
    "test_input_embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ccba4a-fa1c-4351-b4a3-368189bff045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To suppress the warning, we can do:\n",
    "test_input_sex = ohe_sex.transform(pd.DataFrame(test_input[:, 1].reshape(1, 1), columns=['Sex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ee25c2-d05d-40e7-aeea-a5421530f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_age = test_input[:,2].reshape(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5faa482a-5f59-4f36-9645-d269939d52fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_transformed = np.concatenate((test_input[:,[0,3,4,5]], test_input_age, test_input_sex, test_input_embarked), axis = 1)\n",
    "test_input_transformed.shape    # No. or rows = 1 and No. of columns = same as while model training we had on transformed data (=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c9e02fd-4cfc-4e45-b831-47b8de4f25ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_input_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a48a06-374e-4b56-9629-f478c832c114",
   "metadata": {},
   "source": [
    "- Output 1 means the user will survive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f84279e-40ba-4235-8a26-d57937cca087",
   "metadata": {},
   "source": [
    "- How complicated was it? Especially in production, where we had to follow the same steps that we followed during model training transformation.\n",
    "- A small change in the training of the model will impact production code. This is one reason why we should use the pipeline. Let us do the same thing with the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f34418-4dfb-4599-b959-b56cbc2aae42",
   "metadata": {},
   "source": [
    "==============================================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
